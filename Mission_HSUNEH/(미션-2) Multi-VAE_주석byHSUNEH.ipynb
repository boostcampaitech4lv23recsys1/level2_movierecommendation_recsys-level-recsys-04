{"cells":[{"cell_type":"markdown","metadata":{"id":"sQG9hL8-UQUP"},"source":["# Multi-VAE\n","\n","이번 미션에서는 [Variational Autoencoders for Collaborative Filtering](https://arxiv.org/abs/1802.05814)에서 제안된 Multi-VAE 기반의 협업 필터링을 구현해보도록 하겠습니다. 다양한 Auto-Encoder 기반의 협업필터링이 제안된 이후에, 가장 강력하다고 평가받는 VAE 기반의 협업 필터링을 이해하는 시간을 갖도록 하겠습니다.\n","\n","- 이 미션은 다음 [코드](https://github.com/younggyoseo/vae-cf-pytorch)를 기반으로 작성되었습니다. 바로 코드를 확인해보지 마시고, 최대한 직접 작성을 해보세요!\n","- 이 미션에서 중요한 부분은 모델 부분입니다. 데이터 전처리 부분은 가볍게 훑어 보시고, 모델 부분을 집중해주세요!\n","- 완성을 해야할 부분은 TODO로 표시가 되어있습니다."]},{"cell_type":"markdown","metadata":{"id":"J7CfnRw7U59C"},"source":["## 1. 초기 세팅"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11383,"status":"ok","timestamp":1670464079058,"user":{"displayName":"김강민","userId":"16082862873898795036"},"user_tz":-540},"id":"EWWEf1mPKdnX","outputId":"627a84be-0adc-4cf2-a9de-478c7e81cad1"},"outputs":[],"source":["## 전처리과정에서 pandas의 버전에 다르게 동작하는 경향이 보여, 이 미션에서는 아래 버전으로 사용하도록하겠습니다.\n","# !pip install pandas==1.0.1"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"bQj6k1mSbxaz"},"outputs":[],"source":["import argparse\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from scipy import sparse\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j3E2IJSMjO_6"},"source":["### 데이터 다운로드\n","이곳에 대회 사이트(AI Stages)에 있는 data의 URL을 입력해주세요. \n","- 데이터 URL은 변경될 수 있습니다.\n","- 예) `!wget https://aistages-prod-server-public.s3.amazonaws.com/app/Competitions/000176/data/data.tar.gz`"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4232,"status":"ok","timestamp":1647318082403,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jJ1hFEoNA7OE","outputId":"b08804c0-9813-4949-f77d-961694e4cc3a"},"outputs":[],"source":["# !wget <대회 데이터 URL>\n","# !tar -xf data.tar.gz"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1647318083899,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"xQ3W0udmbxa3","outputId":"d556fee8-e1e8-4365-9068-551ba45d1aed"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["## 각종 파라미터 세팅\n","parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n","\n","\n","parser.add_argument('--data', type=str, default='/opt/ml/input/data/train',\n","                    help='Movielens dataset location')\n","\n","parser.add_argument('--lr', type=float, default=1e-4,\n","                    help='initial learning rate')\n","parser.add_argument('--wd', type=float, default=0.00,\n","                    help='weight decay coefficient')\n","parser.add_argument('--batch_size', type=int, default=500,\n","                    help='batch size')\n","parser.add_argument('--epochs', type=int, default=20,\n","                    help='upper epoch limit')\n","parser.add_argument('--total_anneal_steps', type=int, default=200000,\n","                    help='the total number of gradient updates for annealing')\n","parser.add_argument('--anneal_cap', type=float, default=0.2,\n","                    help='largest annealing parameter')\n","parser.add_argument('--seed', type=int, default=1111,\n","                    help='random seed')\n","parser.add_argument('--cuda', action='store_true',\n","                    help='use CUDA')\n","parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n","                    help='report interval')\n","parser.add_argument('--save', type=str, default='model.pt',\n","                    help='path to save the final model')\n","args = parser.parse_args([])\n","\n","# Set the random seed manually for reproductibility.\n","torch.manual_seed(args.seed)\n","\n","#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n","if torch.cuda.is_available():\n","    args.cuda = True\n","\n","device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n","device"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7o1fvXqFWE_G"},"source":["## 2. 데이터 전처리\n","\n","이 부분에서 진행되는 과정은 저희가 일반적으로 알고있는 MovieLens (user, item, timestamp)데이터를 전처리하는 과정입니다. 전처리 과정의 다양한 옵션들을 구성하기 위해 약간 복잡하게 되었지만, \n","결과적으로는, 유저들의 특정한 아이템들을 따로 분리를 해서, 그 분리된 값을 모델이 예측할 수 있냐를 확인하기 위한 전처리 과정이라고 보시면 되겠습니다.\n","실제로 나오는 데이터셋을 확인하면 더욱 이해가 빠를것입니다."]},{"cell_type":"code","execution_count":91,"metadata":{"id":"cgvNoy1Ybxa6"},"outputs":[],"source":["import os\n","import pandas as pd\n","from scipy import sparse\n","import numpy as np\n","\n","# 데이터 tp 의 항목 id 가 몇개인지 세주는 함수\n","def get_count(tp, id):\n","    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n","    count = playcount_groupbyid.size()\n","\n","    return count\n","\n","# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n","# 데이터만을 추출할 때 사용하는 함수입니다.\n","# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n","\n","# 최소 유저, 아이템 이상의 데이터들만 뽑아서 데이터 변환. count 도 포함해서 return\n","def filter_triplets(tp, min_uc=5, min_sc=0):\n","    if min_sc > 0:\n","        itemcount = get_count(tp, 'item')\n","        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n","\n","    if min_uc > 0:\n","        usercount = get_count(tp, 'user')\n","        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n","\n","    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n","    return tp, usercount, itemcount\n","\n","#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n","#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n","#확인하기 위함입니다.\n","def split_train_test_proportion(data, test_prop=0.2):\n","    #데이터를 유저별로 묶고\n","    data_grouped_by_user = data.groupby('user')\n","    tr_list, te_list = list(), list()\n","\n","    np.random.seed(98765)\n","    \n","    for _, group in data_grouped_by_user:\n","        n_items_u = len(group)\n","        \n","        #평가 5개 이상인 것들은 \n","        if n_items_u >= 5:\n","            # 전체 False 인 numpy 생성\n","            idx = np.zeros(n_items_u, dtype='bool')\n","            #test_prop 비율 만큼 랜덤으로 True 값으로 변경\n","            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n","\n","            tr_list.append(group[np.logical_not(idx)])\n","            te_list.append(group[idx])\n","        \n","        #평가 5개이하 한것들은 train으로\n","        else:\n","            tr_list.append(group)\n","    \n","    data_tr = pd.concat(tr_list)\n","    data_te = pd.concat(te_list)\n","\n","    return data_tr, data_te\n","\n","def numerize(tp, profile2id, show2id):\n","    uid = tp['user'].apply(lambda x: profile2id[x])\n","    sid = tp['item'].apply(lambda x: show2id[x])\n","    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"]},{"cell_type":"code","execution_count":92,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4637,"status":"ok","timestamp":1647318092923,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"fVFoRHrmVQsp","outputId":"bb4178bc-0dcc-454b-eddb-10f83179f778"},"outputs":[{"name":"stdout","output_type":"stream","text":["Load and Preprocess Movielens dataset\n","원본 데이터\n","            user   item        time\n","0            11   4643  1230782529\n","1            11    170  1230782534\n","2            11    531  1230782539\n","3            11    616  1230782542\n","4            11   2140  1230782563\n","...         ...    ...         ...\n","5154466  138493  44022  1260209449\n","5154467  138493   4958  1260209482\n","5154468  138493  68319  1260209720\n","5154469  138493  40819  1260209726\n","5154470  138493  27311  1260209807\n","\n","[5154471 rows x 3 columns]\n","5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n","            user   item        time\n","0            11   4643  1230782529\n","1            11    170  1230782534\n","2            11    531  1230782539\n","3            11    616  1230782542\n","4            11   2140  1230782563\n","...         ...    ...         ...\n","5154466  138493  44022  1260209449\n","5154467  138493   4958  1260209482\n","5154468  138493  68319  1260209720\n","5154469  138493  40819  1260209726\n","5154470  138493  27311  1260209807\n","\n","[5154471 rows x 3 columns]\n","유저별 리뷰수\n"," user\n","11        376\n","14        180\n","18         77\n","25         91\n","31        154\n","         ... \n","138473     63\n","138475    124\n","138486    137\n","138492     68\n","138493    314\n","Length: 31360, dtype: int64\n","아이템별 리뷰수\n"," item\n","1         12217\n","2          3364\n","3           734\n","4            43\n","5           590\n","          ...  \n","118700       54\n","118900       60\n","118997       52\n","119141      122\n","119145       78\n","Length: 6807, dtype: int64\n"]}],"source":["print(\"Load and Preprocess Movielens dataset\")\n","# Load Data\n","DATA_DIR = args.data\n","raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n","print(\"원본 데이터\\n\", raw_data)\n","\n","# Filter Data\n","raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n","#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n","print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n","\n","print(\"유저별 리뷰수\\n\",user_activity)\n","print(\"아이템별 리뷰수\\n\",item_popularity)"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1647318093321,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"7T1dTsWUrffP","outputId":"c3f79dfb-8854-4894-bd36-dc07d5f9ee93"},"outputs":[{"name":"stdout","output_type":"stream","text":["(BEFORE) unique_uid: Int64Index([    11,     14,     18,     25,     31,     35,     43,     50,\n","                58,     60,\n","            ...\n","            138459, 138461, 138470, 138471, 138472, 138473, 138475, 138486,\n","            138492, 138493],\n","           dtype='int64', name='user', length=31360)\n","(AFTER) unique_uid: Int64Index([ 27968,  67764,   2581,  82969, 137831,  48639,  97870,  40424,\n","             46835,  79570,\n","            ...\n","            114284,   9009,  21165,  33920,  22054, 135379, 125855,  41891,\n","             15720,  17029],\n","           dtype='int64', name='user', length=31360)\n","훈련 데이터에 사용될 사용자 수: 25360\n","검증 데이터에 사용될 사용자 수: 3000\n","테스트 데이터에 사용될 사용자 수: 3000\n","제출 데이터에 사용될 사용자 수: 31360\n"]}],"source":["# Shuffle User Indices\n","unique_uid = user_activity.index\n","print(\"(BEFORE) unique_uid:\",unique_uid)\n","np.random.seed(98765)\n","idx_perm = np.random.permutation(unique_uid.size)\n","unique_uid = unique_uid[idx_perm]\n","print(\"(AFTER) unique_uid:\",unique_uid)\n","\n","n_users = unique_uid.size #31360\n","n_heldout_users = 3000\n","\n","\n","# Split Train/Validation/Test User Indices\n","tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n","vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n","te_users = unique_uid[(n_users - n_heldout_users):]\n","sub_users = unique_uid\n","#주의: 데이터의 수가 아닌 사용자의 수입니다!\n","print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n","print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n","print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))\n","print(\"제출 데이터에 사용될 사용자 수:\", len(sub_users))"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20754,"status":"ok","timestamp":1647318114955,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"3yBsRCRqtPz6","outputId":"1f8c7e6e-6ff0-42d6-bb9a-367dfc5d16bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Done!\n"]}],"source":["#훈련 데이터에 해당하는 아이템들\n","# Train에는 전체 데이터를 사용합니다.\n","train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n","\n","sub_plays = raw_data.loc[raw_data['user'].isin(sub_users)]\n","\n","#아이템 ID\n","unique_sid = pd.unique(train_plays['item'])\n","unique_sub_sid = pd.unique(sub_plays['item'])\n","\n","id2user = dict((i, pid) for (i, pid) in enumerate(pd.unique(sub_plays['user'])))\n","id2item = dict((i, pid) for (i, pid) in enumerate(pd.unique(sub_plays['item'])))\n","\n","show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n","profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","\n","sub_show2id = dict((sid, i) for (i, sid) in enumerate(unique_sub_sid))\n","sub_profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n","\n","pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n","\n","if not os.path.exists(pro_dir):\n","    os.makedirs(pro_dir)\n","\n","with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n","    for sid in unique_sid:\n","        f.write('%s\\n' % sid)\n","\n","with open(os.path.join(pro_dir, 'unique_sub_sid.txt'), 'w') as f:\n","    for sid in unique_sub_sid:\n","        f.write('%s\\n' % sid)\n","\n","# Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n","vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n","vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n","vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n","\n","test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n","test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n","test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n","\n","\n","\n","train_data = numerize(train_plays, profile2id, show2id)\n","train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n","\n","sub_data = numerize(sub_plays, sub_profile2id, sub_show2id)\n","sub_data.to_csv(os.path.join(pro_dir, 'sub.csv'), index=False)\n","\n","\n","vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n","vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n","\n","vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n","vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n","\n","test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n","test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n","\n","test_data_te = numerize(test_plays_te, profile2id, show2id)\n","test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n","\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":95,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1647318114956,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"jkdg2OkjqVUM","outputId":"393ce3ea-8f6a-4681-de4b-4c25eef547db"},"outputs":[{"name":"stdout","output_type":"stream","text":["           uid   sid\n","0        11825     0\n","1        11825     1\n","2        11825     2\n","3        11825     3\n","4        11825     4\n","...        ...   ...\n","5154466  10783   477\n","5154467  10783  1325\n","5154468  10783   331\n","5154469  10783   558\n","5154470  10783  1922\n","\n","[4168598 rows x 2 columns]\n","           uid   sid\n","376      26554   440\n","377      26554   741\n","378      26554  1407\n","379      26554   193\n","380      26554  1041\n","...        ...   ...\n","5153247  26934   760\n","5153248  26934   697\n","5153249  26934  3245\n","5153250  26934  1369\n","5153251  26934  3691\n","\n","[397924 rows x 2 columns]\n","           uid   sid\n","382      26554  3025\n","383      26554  1681\n","384      26554   201\n","399      26554  3190\n","401      26554  3301\n","...        ...   ...\n","5153233  26934   228\n","5153234  26934  1126\n","5153236  26934   235\n","5153242  26934   209\n","5153244  26934  1792\n","\n","[98001 rows x 2 columns]\n"]}],"source":["#데이터 셋 확인\n","print(train_data)\n","print(vad_data_tr)\n","print(vad_data_te)\n","# print(test_data_tr)\n","# print(test_data_te)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SMiq9leyWWL1"},"source":["## 3. 데이터 로더 설정"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"nxUADr9ibxa8"},"outputs":[],"source":["\n","class DataLoader():\n","    '''\n","    Load Movielens dataset\n","    '''\n","    def __init__(self, path):\n","        \n","        self.pro_dir = os.path.join(path, 'pro_sg')\n","        #error 설정\n","        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n","        # load_n_items 를 통해 이전에 저장해뒀던 아이템의 랜덤 순서 불러옴\n","        self.n_items = self.load_n_items()\n","    \n","    def load_data(self, datatype='train'):\n","        if datatype == 'train':\n","            return self._load_train_data()\n","        elif datatype == 'validation':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'test':\n","            return self._load_tr_te_data(datatype)\n","        elif datatype == 'sub':\n","            return self._load_train_data(datatype)\n","        else:\n","            raise ValueError(\"datatype should be in [train, validation, test, submission]\")\n","    \n","    # self.n_items 에 이전에 저장해뒀던 아이템의 랜덤순서 가져다주는 함수\n","    def load_n_items(self):\n","        unique_sid = list()\n","        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n","            for line in f:\n","                unique_sid.append(line.strip())\n","        n_items = len(unique_sid)\n","        return n_items\n","    \n","    def _load_train_data(self, datatype = 'train'):\n","        path = os.path.join(self.pro_dir, f'{datatype}.csv')\n","        \n","        tp = pd.read_csv(path)\n","        n_users = tp['uid'].max() + 1\n","\n","        rows, cols = tp['uid'], tp['sid']\n","        #compressed sparse row matrix로 변환하기 (희소행렬을 다른식으로 변환하여 저장하는 방법)\n","        data = sparse.csr_matrix((np.ones_like(rows),\n","                                 (rows, cols)), dtype='float64',\n","                                 shape=(n_users, self.n_items))\n","        return data\n","    \n","    def _load_tr_te_data(self, datatype='test'):\n","        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n","        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n","\n","        tp_tr = pd.read_csv(tr_path)\n","        tp_te = pd.read_csv(te_path)\n","\n","        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n","        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n","\n","        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n","        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n","\n","        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n","                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n","                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n","        return data_tr, data_te"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6FHhwKqXWaUZ"},"source":["## 4. 모델정의\n","\n","VAE 코드 참고: https://atcold.github.io/pytorch-Deep-Learning/ko/week08/08-3/\n","\n","multi-vae 는 multinomial likelihood를 사용하기 때문에 implicit feedback data를 더 잘 설명할 수 있다고 한다.\n","\n","Multi-vae 이론 참고: https://velog.io/@2712qwer/Paper-Code-Review-2018-WWW-Variational-Autoencoders-for-Collaborative-Filtering"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"QYlGPJTYU0ii"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","import numpy as np\n","\n","\n","#이미 완성된 MultiDAE(denoising auto encoder)의 코드를 참고하여 그 아래 MultiVAE의 코드를 완성해보세요!\n","class MultiDAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-DAE.\n","\n","    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiDAE, self).__init__()\n","        #p_dims, q_dims 는 input, output dimension 리스트\n","        #p_dims = [200, 600, 6807]\n","        self.p_dims = p_dims\n","        #q_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        # q_dims 없으면 p_dims 순서 뒤집어서 사용\n","        else:\n","            self.q_dims = p_dims[::-1]\n","        # 항목이 5개가 되게 함\n","        self.dims = self.q_dims + self.p_dims[1:]\n","        # nn.Sequential 과 비슷한함수로, Module 여러개 담아놓는 역할\n","        # nn.Linear(6807, 600), nn.Linear(600,200),nn.Linear(200, 600),nn.Linear(600,6807)\n","        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n","        self.drop = nn.Dropout(dropout)\n","        \n","        self.init_weights()\n","    \n","    def forward(self, input):\n","        #input 정규화 (이유 : 학습 속도 높이고, Local optimum에 빠지게 하지 않기 위해)\n","        #input dropout 으로 몇가닥 끊기(과적합 방지)\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        #nn.Module에 저장해 뒀던 Linear 함수 적용\n","        for i, layer in enumerate(self.layers):\n","            h = layer(h)\n","            # 마지막 항에서는 tanh로 activation function 적용\n","            if i != len(self.layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        # 가중치 초기화 하는 함수 \n","        for layer in self.layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            # 가중치 함수 초기화 (평균=0 , 표준편차 = std)\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","def loss_function_dae(recon_x, x):\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    return BCE\n","\n","\n","\n","# TODO\n","# 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","# https://github.com/AntixK/PyTorch-VAE\n","class MultiVAE(nn.Module):\n","    \"\"\"\n","    Container module for Multi-VAE.\n","\n","    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n","    See Variational Autoencoders for Collaborative Filtering\n","    https://arxiv.org/abs/1802.05814\n","    \"\"\"\n","\n","    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n","        super(MultiVAE, self).__init__()\n","        # init 부분은 Multi DAE 와 동일\n","        self.p_dims = p_dims\n","        if q_dims:\n","            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n","            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n","            self.q_dims = q_dims\n","        else:\n","            self.q_dims = p_dims[::-1]\n","\n","        # Last dimension of q- network is for mean and variance\n","        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n","        # encoder 용 : q_layers는 p_dims 뒤집고 마지막항 한번더 연산추가한 Linear layer 들의 결합\n","        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n","        # decoder 용 : p_layer는 p_dims 그대로 사용한 Linear layer 들의 결합으로\n","        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n","            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n","        \n","        self.drop = nn.Dropout(dropout)\n","        self.init_weights()\n","    \n","    # 인풋 -> 인코더 ->  파라미터 재정비 -> 디코더 -> 아웃풋 + 인코더 결과물(mu, logvar)\n","    def forward(self, input):\n","        mu, logvar = self.encode(input)\n","        z = self.reparameterize(mu, logvar)\n","        h = self.decode(z)\n","        return h, mu, logvar\n","    \n","    def encode(self, input):\n","        h = F.normalize(input)\n","        h = self.drop(h)\n","        #인코더에서는 MultiDAE 처럼 linear layer 돌림\n","        for i, layer in enumerate(self.q_layers):\n","            h = layer(h)\n","            if i != len(self.q_layers) - 1:\n","                h = F.tanh(h)\n","            else:\n","                # mu : 평균\n","                # logvar : log 분산 (표준편차가 음수가 되지 않기 위한 연산)\n","                # 처음 값들은 평균(mu)로 보내고 나머지 값들은 분산으로 보냄\n","                # h 는 [항목수, linear 로 변환된 dim]\n","                mu = h[:, :self.q_dims[-1]]\n","                logvar = h[:, self.q_dims[-1]:]\n","                # 이후 reparameterize 에서 연산처리함\n","        return mu, logvar\n","\n","    # training 과정에서 역전파를 수행할 수 있도록 재매개변수화 함수를 따로 생성했다고 함.\n","    def reparameterize(self, mu, logvar):\n","        # 학습중일 때는 평균 중심으로 분산 흩뿌려서 제출\n","        if self.training:\n","            #logvar로 표준편차 계산\n","            std = torch.exp(0.5 * logvar)\n","            # std를 정규분포 값으로 초기화한 eps\n","            eps = torch.randn_like(std)\n","            return eps.mul(std).add_(mu)\n","        # 아닐 때는 그냥 평균값 배출\n","        else:\n","            return mu\n","\n","    def decode(self, z):\n","        h = z\n","        for i, layer in enumerate(self.p_layers):\n","            h = layer(h)\n","            if i != len(self.p_layers) - 1:\n","                h = F.tanh(h)\n","        return h\n","\n","    def init_weights(self):\n","        for layer in self.q_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","        \n","        for layer in self.p_layers:\n","            # Xavier Initialization for weights\n","            size = layer.weight.size()\n","            fan_out = size[0]\n","            fan_in = size[1]\n","            std = np.sqrt(2.0/(fan_in + fan_out))\n","            layer.weight.data.normal_(0.0, std)\n","\n","            # Normal Initialization for Biases\n","            layer.bias.data.normal_(0.0, 0.001)\n","\n","\n","\n","def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n","    # Loss function은 BCE와 KLD 사용\n","    # KL annealing 을 통해 Regularization 부여\n","    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n","    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n","    # anneal 값을 0에서부터 특정 값까지 선형적으로 증가시켜 \n","    # 학습 초기에 reconstruction term을 강조하여 보다 효율적인 학습 도모함.\n","    return BCE + anneal * KLD\n","\n","\n"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"7nEfVTktbxa8"},"outputs":[],"source":["# 단순하게 torch.FloatTensor 쓰는 함수\n","def naive_sparse2tensor(data):\n","    return torch.FloatTensor(data.toarray())\n","\n","# 위 함수를 변형한 함수 (속도 개선)\n","# 근데 조교님 정답에선 이거 안씀\n","# 어떻게 쓰는 건지 모르겠음\n","def sparse2torch_sparse(data):\n","    \"\"\"\n","    scipy 행렬에서 torch 희소행렬로 L2 Norm을 이용하여 변환\n","    이렇게 하면 단순하게 torch.FloatTensor(data.toarray())를 쓰는 것 보다 빨라짐\n","    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n","    \"\"\"\n","    samples = data.shape[0]\n","    features = data.shape[1]\n","    # coo행렬은 coordinate format을 이용하여 희소행렬을 표현하는 방법\n","    # 원소의 좌표와 data 를 함께 넘겨줌\n","    # 참고 https://radish-greens.tistory.com/1\n","    coo_data = data.tocoo()\n","    indices = torch.LongTensor([coo_data.row, coo_data.col])\n","    row_norms_inv = 1 / np.sqrt(data.sum(1))\n","    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n","    values = np.array([row2val[r] for r in coo_data.row])\n","    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n","    return t\n","\n","\n","def train(model, criterion, optimizer, is_VAE = False):\n","    # Turn on training mode\n","    model.train()\n","    train_loss = 0.0\n","    start_time = time.time()\n","    global update_count\n","    # idxlist, N 는 아래 코드에서 따온 변수임\n","        # train_data = loader.load_data('train')\n","        # N = train_data.shape[0] : train data의 크기\n","        # idxlist = list(range(N)) : train data 크기만큼 range list\n","    \n","    # idxlist 를 랜덤으로 섞는다\n","    np.random.shuffle(idxlist)\n","    \n","    # 배치 단위로 잘라서 학습\n","    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n","        # 끝부분 처리\n","        end_idx = min(start_idx + args.batch_size, N)\n","        # 랜덤으로 섞인 train_data 배치사이즈로 자르기\n","        data = train_data[idxlist[start_idx:end_idx]]\n","        # 텐서로 변환\n","        data = naive_sparse2tensor(data).to(device)\n","        optimizer.zero_grad()# 모든 매개변수의 변화도 버퍼를 0으로 만듦\n","\n","        # Multi-VAE\n","        if is_VAE:\n","            #Default = 200000\n","            if args.total_anneal_steps > 0:\n","                anneal = min(args.anneal_cap, \n","                                1. * update_count / args.total_anneal_steps)\n","            else:\n","                anneal = args.anneal_cap # default = 0.2\n","\n","            # TODO\n","            # model에 입력 출력 코드를 작성해주세요\n","            recon_batch, mu, logvar = model(data)\n","\n","            # loss 함수를 설정해주세요        \n","            # criterion 은 loss_function_vae 가 들어옴\n","            loss = criterion(recon_batch, data, mu, logvar, anneal)\n","\n","        #Multi-DAE는 else로 처리\n","        else:\n","          recon_batch = model(data)\n","          loss = criterion(recon_batch, data)\n","\n","        loss.backward()             # 역전파\n","        train_loss += loss.item()   # loss 값 적립\n","        optimizer.step()            # 업데이트 진행\n","\n","        update_count += 1\n","\n","        # 100 번(Log_interval) 마다 실행\n","        # 근데 배치가 51개로 설정되어 있어서 10으로 바꿔 쓰면 그제야 실행됨\n","        if batch_idx % args.log_interval == 0 and batch_idx > 0: # log_interval : default=100\n","            elapsed = time.time() - start_time\n","            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n","                    'loss {:4.2f}'.format(\n","                        epoch, \n","                        batch_idx, len(range(0, N, args.batch_size)),\n","                        elapsed * 1000 / args.log_interval,\n","                        train_loss / args.log_interval))\n","            \n","\n","            start_time = time.time()\n","            train_loss = 0.0\n","\n","\n","def evaluate(model, criterion, data_tr, data_te, is_VAE=False):\n","    # Turn on evaluation mode\n","    model.eval()\n","    total_loss = 0.0\n","    global update_count\n","    \n","    # 테스트 리스트\n","    e_idxlist = list(range(data_tr.shape[0]))\n","    e_N = data_tr.shape[0]\n","    n100_list = []\n","    r20_list = []\n","    r50_list = []\n","    \n","    # 학습 아닐때 no_grad 써주기\n","    with torch.no_grad():\n","        # 배치 크기로 자르기\n","        for start_idx in range(0, e_N, args.batch_size):\n","            # 배치 끝처리\n","            end_idx = min(start_idx + args.batch_size, N)\n","            # 테스트의 트레인 데이터 자르기\n","            data = data_tr[e_idxlist[start_idx:end_idx]]\n","            # 테스트의 테스트 데이터 불러오기\n","            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n","\n","            data_tensor = naive_sparse2tensor(data).to(device)\n","            \n","            # Multi-VAE\n","            if is_VAE :\n","                if args.total_anneal_steps > 0:\n","                    anneal = min(args.anneal_cap, \n","                                    1. * update_count / args.total_anneal_steps)\n","                else:\n","                    anneal = args.anneal_cap\n","                \n","                #TODO\n","                #model에 입력 출력 코드를 작성해주세요\n","                recon_batch, mu, logvar = model(data_tensor)\n","                #loss 함수를 설정해주세요\n","                loss = criterion(recon_batch, data_tensor, mu, logvar, anneal)\n","\n","            # Multi-DAE\n","            else :\n","                recon_batch = model(data_tensor)\n","                loss = criterion(recon_batch, data_tensor)\n","\n","\n","            total_loss += loss.item()\n","\n","            # Exclude examples from training set\n","            # 모델일 때는 cpu(), 텐서일 때는 cuda()로 쓴다고 함\n","            recon_batch = recon_batch.cpu().numpy()\n","            # data.nonzero() -> 배치단위로 잘린 데이터중 0이 아닌 값의 Index 값\n","            # 테스트의 트레인 데이터 값들을 마이너스 무한대로 변환\n","            recon_batch[data.nonzero()] = -np.inf\n","\n","            # 평가 (METRIC)\n","            # 100개의 배치로 계산한 NDCG\n","            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n","            # 20개 배치로 계산한 Recall@K\n","            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n","            # 50개 배치로 계산한 Recall@K\n","            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n","\n","            n100_list.append(n100)\n","            r20_list.append(r20)\n","            r50_list.append(r50)\n","    # loss 배치 단위로 평균내기\n","    total_loss /= len(range(0, e_N, args.batch_size))\n","    n100_list = np.concatenate(n100_list)\n","    r20_list = np.concatenate(r20_list)\n","    r50_list = np.concatenate(r50_list)\n","\n","    return total_loss, np.mean(n100_list), np.mean(r20_list), np.mean(r50_list)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JOsCJbb_X9gl"},"source":["### Metric 정의"]},{"cell_type":"code","execution_count":99,"metadata":{"id":"zxNtit6vbxa-"},"outputs":[],"source":["import bottleneck as bn\n","import numpy as np\n","\n","def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n","    '''\n","    Normalized Discounted Cumulative Gain@k for binary relevance\n","    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n","    '''\n","    # 마이너스 무한대 값이 들어있는 X_pred, 테스트 데이터가 들어있는 heldout_batch\n","    batch_users = X_pred.shape[0]\n","    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n","    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n","                       idx_topk_part[:, :k]]\n","    idx_part = np.argsort(-topk_part, axis=1)\n","\n","    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n","\n","    tp = 1. / np.log2(np.arange(2, k + 2))\n","\n","    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n","                         idx_topk].toarray() * tp).sum(axis=1)\n","    IDCG = np.array([(tp[:min(n, k)]).sum()\n","                     for n in heldout_batch.getnnz(axis=1)])\n","    return DCG / IDCG\n","\n","\n","def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n","    batch_users = X_pred.shape[0]\n","\n","    idx = bn.argpartition(-X_pred, k, axis=1)\n","    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n","    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n","\n","    X_true_binary = (heldout_batch > 0).toarray()\n","    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n","        np.float32)\n","    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n","    return recall"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cDD7lD7sHcnH"},"source":["## MultiDAE 테스트"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"WLYyTwToX4fm"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiDAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_dae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50098,"status":"ok","timestamp":1647318176188,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"6rOEDs2Lbxa-","outputId":"6fb9eb56-26a4-45aa-d867-84dacf7b1e0a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 1.62s | valid loss 999.38 | n100 0.296 | r20 0.218 | r50 0.268\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 1.63s | valid loss 971.19 | n100 0.338 | r20 0.252 | r50 0.309\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 1.63s | valid loss 958.05 | n100 0.365 | r20 0.276 | r50 0.334\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 1.73s | valid loss 949.21 | n100 0.381 | r20 0.288 | r50 0.348\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 1.65s | valid loss 943.27 | n100 0.389 | r20 0.296 | r50 0.358\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 1.87s | valid loss 939.49 | n100 0.397 | r20 0.302 | r50 0.364\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 1.77s | valid loss 936.03 | n100 0.402 | r20 0.307 | r50 0.371\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 1.80s | valid loss 932.69 | n100 0.409 | r20 0.313 | r50 0.379\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 1.81s | valid loss 929.80 | n100 0.414 | r20 0.320 | r50 0.383\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 1.76s | valid loss 926.93 | n100 0.418 | r20 0.321 | r50 0.387\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 1.76s | valid loss 925.01 | n100 0.422 | r20 0.325 | r50 0.390\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time: 1.74s | valid loss 922.83 | n100 0.423 | r20 0.326 | r50 0.392\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time: 1.64s | valid loss 921.14 | n100 0.424 | r20 0.326 | r50 0.394\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time: 1.69s | valid loss 919.56 | n100 0.430 | r20 0.332 | r50 0.398\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time: 1.71s | valid loss 917.94 | n100 0.432 | r20 0.334 | r50 0.399\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 1.67s | valid loss 916.30 | n100 0.433 | r20 0.334 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time: 1.65s | valid loss 914.78 | n100 0.432 | r20 0.333 | r50 0.401\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time: 1.74s | valid loss 913.33 | n100 0.435 | r20 0.336 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time: 1.75s | valid loss 912.13 | n100 0.433 | r20 0.335 | r50 0.403\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time: 1.67s | valid loss 910.92 | n100 0.431 | r20 0.331 | r50 0.402\n","-----------------------------------------------------------------------------------------\n"]}],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=False)\n","    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=False)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(\"MultiDAE.pt\", 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# # Load the best saved model.\n","# with open(args.save, 'rb') as f:\n","#     model = torch.load(f)\n","\n","# # Run on test data.\n","# test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=False)\n","# print('=' * 89)\n","# print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n","#         'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n","# print('=' * 89)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["def predict(model, data_tr, is_VAE=False):\n","    model.eval()\n","    global update_count\n","    users = []\n","    items = []\n","    with torch.no_grad():\n","        for start_idx in range(data_tr.shape[0]):\n","            data = data_tr[start_idx]\n","            data_tensor = naive_sparse2tensor(data).to(device)            \n","            # Multi-VAE\n","            if is_VAE :        \n","                recon_batch, mu, logvar = model(data_tensor)\n","            # Multi-DAE\n","            else:\n","                recon_batch = model(data_tensor)\n","            recon_batch = recon_batch.cpu().numpy()\n","            recon_batch[data.nonzero()] = -np.inf\n","            \n","            for rec in recon_batch:\n","                up = np.argpartition(rec, -10)[-10:].tolist()\n","                users.extend([start_idx] * 10)\n","                items.extend(up)\n","    user2rec_list = pd.DataFrame({'user': users, 'item': items}, dtype=int)\n","    return user2rec_list"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>11</td>\n","      <td>994</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>2968</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11</td>\n","      <td>5747</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>6197</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11</td>\n","      <td>6874</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>313591</th>\n","      <td>138493</td>\n","      <td>4022</td>\n","    </tr>\n","    <tr>\n","      <th>313596</th>\n","      <td>138493</td>\n","      <td>8580</td>\n","    </tr>\n","    <tr>\n","      <th>313590</th>\n","      <td>138493</td>\n","      <td>25752</td>\n","    </tr>\n","    <tr>\n","      <th>313592</th>\n","      <td>138493</td>\n","      <td>33794</td>\n","    </tr>\n","    <tr>\n","      <th>313598</th>\n","      <td>138493</td>\n","      <td>58559</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>313600 rows × 2 columns</p>\n","</div>"],"text/plain":["          user   item\n","6           11    994\n","4           11   2968\n","2           11   5747\n","0           11   6197\n","5           11   6874\n","...        ...    ...\n","313591  138493   4022\n","313596  138493   8580\n","313590  138493  25752\n","313592  138493  33794\n","313598  138493  58559\n","\n","[313600 rows x 2 columns]"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["with open(\"MultiDAE.pt\", 'rb') as f:\n","    model = torch.load(f)    \n","sub_data = loader.load_data('sub')\n","user2rec_list = predict(model, sub_data, is_VAE=False)\n","user2rec_list['user'] = user2rec_list['user'].map(id2user)\n","user2rec_list['item'] = user2rec_list['item'].map(id2item)\n","Multi_DAE = user2rec_list.sort_values(by=['user','item'])\n","Multi_DAE"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["Multi_DAE.to_csv(os.path.join(\"../output/\", 'MultiDAE.csv'), index = False)"]},{"cell_type":"markdown","metadata":{"id":"o1QjCbMBXw4v"},"source":["## MultiVAE 테스트 (TODO)\n","\n","- 위의 MultiVAE 모델 코드, train, evaluate 함수를 완성하여, 아래 훈련 코드가 정상적으로 동작하도록 해보세요!\n","- 다양한 VAE의 코드를 다음 코드를 확인한 뒤에, 아래코드에 맞춰서 직접 작성해보는 연습을 해보세요!\n","  - https://github.com/AntixK/PyTorch-VAE\n","- 완성해야할 함수\n","  - MultiVAE class\n","    - forward\n","    - encode\n","    - decode\n","  - train\n","  - evaluate"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4941,"status":"ok","timestamp":1646922488386,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"78zFFNzgbxa_","outputId":"2d6d4723-d2db-4edc-b11b-a64b9ea95943"},"outputs":[],"source":["\n","###############################################################################\n","# Load data\n","###############################################################################\n","\n","loader = DataLoader(args.data)\n","\n","n_items = loader.load_n_items()\n","train_data = loader.load_data('train')\n","vad_data_tr, vad_data_te = loader.load_data('validation')\n","test_data_tr, test_data_te = loader.load_data('test')\n","\n","N = train_data.shape[0]\n","idxlist = list(range(N))\n","\n","###############################################################################\n","# Build the model\n","###############################################################################\n","\n","p_dims = [200, 600, n_items]\n","model = MultiVAE(p_dims).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=args.wd)\n","criterion = loss_function_vae\n","\n","###############################################################################\n","# Training code\n","###############################################################################\n","\n","best_n100 = -np.inf\n","update_count = 0"]},{"cell_type":"code","execution_count":106,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":7,"status":"error","timestamp":1646922488389,"user":{"displayName":"Jungwon Seo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh-5uwnfogZleKrsyZupiP0LpS_PBPloa_pqKvqTg=s64","userId":"00987919963196484028"},"user_tz":-540},"id":"WoUFwndCvvtp","outputId":"4e50e9d7-8317-4d4f-8449-d384176378b8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"name":"stdout","output_type":"stream","text":["-----------------------------------------------------------------------------------------\n","| end of epoch   1 | time: 1.55s | valid loss 1024.07 | n100 0.267 | r20 0.197 | r50 0.244\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   2 | time: 1.56s | valid loss 982.02 | n100 0.316 | r20 0.236 | r50 0.292\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   3 | time: 1.57s | valid loss 969.88 | n100 0.339 | r20 0.254 | r50 0.311\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   4 | time: 1.55s | valid loss 961.47 | n100 0.359 | r20 0.272 | r50 0.331\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   5 | time: 1.58s | valid loss 953.71 | n100 0.371 | r20 0.280 | r50 0.340\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   6 | time: 1.62s | valid loss 946.48 | n100 0.385 | r20 0.292 | r50 0.354\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   7 | time: 1.62s | valid loss 943.13 | n100 0.390 | r20 0.295 | r50 0.360\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   8 | time: 1.69s | valid loss 940.08 | n100 0.397 | r20 0.303 | r50 0.365\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch   9 | time: 1.79s | valid loss 937.39 | n100 0.400 | r20 0.304 | r50 0.369\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  10 | time: 1.75s | valid loss 935.67 | n100 0.402 | r20 0.307 | r50 0.373\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  11 | time: 1.69s | valid loss 933.58 | n100 0.408 | r20 0.313 | r50 0.376\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  12 | time: 1.75s | valid loss 931.64 | n100 0.412 | r20 0.315 | r50 0.380\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  13 | time: 1.76s | valid loss 929.90 | n100 0.413 | r20 0.318 | r50 0.383\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  14 | time: 1.78s | valid loss 928.43 | n100 0.417 | r20 0.320 | r50 0.386\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  15 | time: 1.77s | valid loss 927.21 | n100 0.417 | r20 0.320 | r50 0.388\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  16 | time: 1.89s | valid loss 926.36 | n100 0.419 | r20 0.320 | r50 0.389\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  17 | time: 1.83s | valid loss 925.13 | n100 0.421 | r20 0.323 | r50 0.391\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  18 | time: 1.73s | valid loss 924.36 | n100 0.423 | r20 0.325 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  19 | time: 1.78s | valid loss 923.38 | n100 0.423 | r20 0.326 | r50 0.393\n","-----------------------------------------------------------------------------------------\n","-----------------------------------------------------------------------------------------\n","| end of epoch  20 | time: 1.68s | valid loss 922.48 | n100 0.425 | r20 0.325 | r50 0.395\n","-----------------------------------------------------------------------------------------\n","=========================================================================================\n","| End of training | test loss 909.33 | n100 0.42 | r20 0.33 | r50 0.40\n","=========================================================================================\n"]}],"source":["for epoch in range(1, args.epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model, criterion, optimizer, is_VAE=True)\n","    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te, is_VAE=True)\n","    print('-' * 89)\n","    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n","            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n","                epoch, time.time() - epoch_start_time, val_loss,\n","                n100, r20, r50))\n","    print('-' * 89)\n","\n","    n_iter = epoch * len(range(0, N, args.batch_size))\n","\n","\n","    # Save the model if the n100 is the best we've seen so far.\n","    if n100 > best_n100:\n","        with open(\"MultiVAE.pt\", 'wb') as f:\n","            torch.save(model, f)\n","        best_n100 = n100\n","\n","\n","\n","# Load the best saved model.\n","with open(\"MultiVAE.pt\", 'rb') as f:\n","    model = torch.load(f)\n","\n","# Run on test data.\n","test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te, is_VAE=True)\n","print('=' * 89)\n","print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n","        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n","print('=' * 89)"]},{"cell_type":"markdown","metadata":{"id":"yc8QsKFkJdHL"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n","\n"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[],"source":["with open(\"MultiVAE.pt\", 'rb') as f:\n","    model = torch.load(f)\n","sub_data = loader.load_data('sub')\n","user2rec_list = predict(model, sub_data, is_VAE=True)\n","user2rec_list['user'] = user2rec_list['user'].map(id2user)\n","user2rec_list['item'] = user2rec_list['item'].map(id2item)\n","Multi_VAE = user2rec_list.sort_values(by=['user','item'])\n","Multi_VAE.to_csv(os.path.join(\"../output/\", 'MultiVAE1.csv'), index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"},"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
